<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://george-ao.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://george-ao.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-04-19T01:30:29+00:00</updated><id>https://george-ao.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Swap policy in vllm</title><link href="https://george-ao.github.io/blog/2024/vllm_swap/" rel="alternate" type="text/html" title="Swap policy in vllm"/><published>2024-04-17T00:00:00+00:00</published><updated>2024-04-17T00:00:00+00:00</updated><id>https://george-ao.github.io/blog/2024/vllm_swap</id><content type="html" xml:base="https://george-ao.github.io/blog/2024/vllm_swap/"><![CDATA[<p>This post is to discuss the swap policy in vllm. In each step of <code class="language-plaintext highlighter-rouge">llm.engine</code>, the <code class="language-plaintext highlighter-rouge">scheduler</code> schedules the blocks to be swapped in and out. Then, the relevant information about the swap-in and swap-out blocks is passed to the <code class="language-plaintext highlighter-rouge">model_executor</code> through <code class="language-plaintext highlighter-rouge">scheduler_outputs</code>.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="n">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">RequestOutput</span><span class="p">]:</span>
        <span class="n">seq_group_metadata_list</span><span class="p">,</span> <span class="n">scheduler_outputs</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">scheduler</span><span class="p">.</span><span class="nf">schedule</span><span class="p">()</span>
        <span class="c1"># pdb.set_trace()
</span>        <span class="k">if</span> <span class="ow">not</span> <span class="n">scheduler_outputs</span><span class="p">.</span><span class="nf">is_empty</span><span class="p">():</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">model_executor</span><span class="p">.</span><span class="nf">execute_model</span><span class="p">(</span>
                <span class="n">seq_group_metadata_list</span><span class="p">,</span> <span class="n">scheduler_outputs</span><span class="p">.</span><span class="n">blocks_to_swap_in</span><span class="p">,</span>
                <span class="n">scheduler_outputs</span><span class="p">.</span><span class="n">blocks_to_swap_out</span><span class="p">,</span>
                <span class="n">scheduler_outputs</span><span class="p">.</span><span class="n">blocks_to_copy</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">output</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="nf">_process_model_outputs</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">scheduler_outputs</span><span class="p">)</span>
</code></pre></div></div> <p>The swap-in and swap-out blocks are decided in <code class="language-plaintext highlighter-rouge">scheduler.schedule()</code> function, which calls <code class="language-plaintext highlighter-rouge">scheduler._schedule()</code>. The scheduler will try to swap in the blocks from cpu to gpu if it is possible. The scheduler will also swap out the blocks from gpu to cpu if <code class="language-plaintext highlighter-rouge">block_manager.can_append_slot</code> fails. In that case, the scheduler will preempt lower priority seq groups to make space for the higher priority seq groups. In vllm, there are two ways to preempt low priority sequence group: <code class="language-plaintext highlighter-rouge">recompute</code> and <code class="language-plaintext highlighter-rouge">swap</code>. According to the code, the current policy is <code class="language-plaintext highlighter-rouge">recompute</code> only when seq_group.get_max_num_running_seqs() == 1. <code class="language-plaintext highlighter-rouge">scheduler.schedule()</code> will return <code class="language-plaintext highlighter-rouge">scheduler_outputs</code> which contains necessary information for <code class="language-plaintext highlighter-rouge">model_executor</code> to do the swap-in and swap-out. Following are the code showcasing what functions model_executor will call:</p> <ol> <li> <p>In <code class="language-plaintext highlighter-rouge">model_executor.execute_model()</code>, it will call <code class="language-plaintext highlighter-rouge">driver_worker</code> to do the job.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   <span class="n">output</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">driver_worker</span><span class="p">.</span><span class="nf">execute_model</span><span class="p">(</span>
   <span class="n">seq_group_metadata_list</span><span class="o">=</span><span class="n">seq_group_metadata_list</span><span class="p">,</span>
   <span class="n">blocks_to_swap_in</span><span class="o">=</span><span class="n">blocks_to_swap_in</span><span class="p">,</span>
   <span class="n">blocks_to_swap_out</span><span class="o">=</span><span class="n">blocks_to_swap_out</span><span class="p">,</span>
   <span class="n">blocks_to_copy</span><span class="o">=</span><span class="n">blocks_to_copy</span><span class="p">,</span>
 <span class="p">)</span>
</code></pre></div> </div> </li> <li> <p>In <code class="language-plaintext highlighter-rouge">worker</code>, it will call <code class="language-plaintext highlighter-rouge">cache_swap</code> (some codes are ommited)</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">is_driver_worker</span><span class="p">:</span>
   <span class="k">assert</span> <span class="n">seq_group_metadata_list</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span>
   <span class="n">num_seq_groups</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">seq_group_metadata_list</span><span class="p">)</span>
   <span class="k">assert</span> <span class="n">blocks_to_swap_in</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span>
   <span class="k">assert</span> <span class="n">blocks_to_swap_out</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span>
   <span class="k">assert</span> <span class="n">blocks_to_copy</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span>
   <span class="n">data</span> <span class="o">=</span> <span class="p">{</span>
       <span class="sh">"</span><span class="s">num_seq_groups</span><span class="sh">"</span><span class="p">:</span> <span class="n">num_seq_groups</span><span class="p">,</span>
       <span class="sh">"</span><span class="s">blocks_to_swap_in</span><span class="sh">"</span><span class="p">:</span> <span class="n">blocks_to_swap_in</span><span class="p">,</span>
       <span class="sh">"</span><span class="s">blocks_to_swap_out</span><span class="sh">"</span><span class="p">:</span> <span class="n">blocks_to_swap_out</span><span class="p">,</span>
       <span class="sh">"</span><span class="s">blocks_to_copy</span><span class="sh">"</span><span class="p">:</span> <span class="n">blocks_to_copy</span><span class="p">,</span>
   <span class="p">}</span>
   <span class="nf">broadcast_tensor_dict</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">src</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
   <span class="n">self</span><span class="p">.</span><span class="nf">cache_swap</span><span class="p">(</span><span class="n">blocks_to_swap_in</span><span class="p">,</span> <span class="n">blocks_to_swap_out</span><span class="p">,</span> <span class="n">blocks_to_copy</span><span class="p">)</span>
</code></pre></div> </div> </li> <li> <p>Then, it will call <code class="language-plaintext highlighter-rouge">cache_engine</code> to swap the blocks.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>     <span class="k">def</span> <span class="nf">swap_in</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">src_to_dst</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
         <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">num_layers</span><span class="p">):</span>
             <span class="n">self</span><span class="p">.</span><span class="n">attn_backend</span><span class="p">.</span><span class="nf">swap_blocks</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">cpu_cache</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">self</span><span class="p">.</span><span class="n">gpu_cache</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
                                         <span class="n">src_to_dst</span><span class="p">)</span>
</code></pre></div> </div> </li> <li>In <code class="language-plaintext highlighter-rouge">attn_backend</code>(xformer in my case), it will call <code class="language-plaintext highlighter-rouge">Pageattention.swap_blocks</code> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>     <span class="k">def</span> <span class="nf">swap_blocks</span><span class="p">(</span>
         <span class="n">src_kv_cache</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span>
         <span class="n">dst_kv_cache</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span>
         <span class="n">src_to_dst</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span>
     <span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
         <span class="n">PagedAttention</span><span class="p">.</span><span class="nf">swap_blocks</span><span class="p">(</span><span class="n">src_kv_cache</span><span class="p">,</span> <span class="n">dst_kv_cache</span><span class="p">,</span> <span class="n">src_to_dst</span><span class="p">)</span>
</code></pre></div> </div> </li> <li>And then it will use <code class="language-plaintext highlighter-rouge">cache_ops</code>.(some codes are ommited) <div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code>     <span class="kt">void</span> <span class="nf">swap_blocks</span><span class="p">(</span>
         <span class="n">torch</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&amp;</span> <span class="n">src</span><span class="p">,</span>
         <span class="n">torch</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&amp;</span> <span class="n">dst</span><span class="p">,</span>
         <span class="k">const</span> <span class="n">std</span><span class="o">::</span><span class="n">map</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="p">,</span> <span class="kt">int64_t</span><span class="o">&gt;&amp;</span> <span class="n">block_mapping</span><span class="p">)</span> <span class="p">{</span>
         <span class="kt">char</span> <span class="o">*</span><span class="n">src_ptr</span> <span class="o">=</span> <span class="k">static_cast</span><span class="o">&lt;</span><span class="kt">char</span><span class="o">*&gt;</span><span class="p">(</span><span class="n">src</span><span class="p">.</span><span class="n">data_ptr</span><span class="p">());</span>
         <span class="kt">char</span> <span class="o">*</span><span class="n">dst_ptr</span> <span class="o">=</span> <span class="k">static_cast</span><span class="o">&lt;</span><span class="kt">char</span><span class="o">*&gt;</span><span class="p">(</span><span class="n">dst</span><span class="p">.</span><span class="n">data_ptr</span><span class="p">());</span>
         <span class="k">const</span> <span class="kt">int64_t</span> <span class="n">block_size_in_bytes</span> <span class="o">=</span> <span class="n">src</span><span class="p">.</span><span class="n">element_size</span><span class="p">()</span> <span class="o">*</span> <span class="n">src</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">numel</span><span class="p">();</span>
         <span class="k">const</span> <span class="n">at</span><span class="o">::</span><span class="n">cuda</span><span class="o">::</span><span class="n">OptionalCUDAGuard</span> <span class="n">device_guard</span><span class="p">(</span><span class="n">src_device</span><span class="p">.</span><span class="n">is_cuda</span><span class="p">()</span> <span class="o">?</span> <span class="n">src_device</span> <span class="o">:</span> <span class="n">dst_device</span><span class="p">);</span>
         <span class="k">const</span> <span class="n">cudaStream_t</span> <span class="n">stream</span> <span class="o">=</span> <span class="n">at</span><span class="o">::</span><span class="n">cuda</span><span class="o">::</span><span class="n">getCurrentCUDAStream</span><span class="p">();</span>
         <span class="c1">// NOTE(woosuk): This can be slow if the number of blocks is large.</span>
         <span class="k">for</span> <span class="p">(</span><span class="k">const</span> <span class="k">auto</span><span class="o">&amp;</span> <span class="n">pair</span> <span class="o">:</span> <span class="n">block_mapping</span><span class="p">)</span> <span class="p">{</span>
             <span class="kt">int64_t</span> <span class="n">src_block_number</span> <span class="o">=</span> <span class="n">pair</span><span class="p">.</span><span class="n">first</span><span class="p">;</span>
             <span class="kt">int64_t</span> <span class="n">dst_block_number</span> <span class="o">=</span> <span class="n">pair</span><span class="p">.</span><span class="n">second</span><span class="p">;</span>
             <span class="kt">int64_t</span> <span class="n">src_offset</span> <span class="o">=</span> <span class="n">src_block_number</span> <span class="o">*</span> <span class="n">block_size_in_bytes</span><span class="p">;</span>
             <span class="kt">int64_t</span> <span class="n">dst_offset</span> <span class="o">=</span> <span class="n">dst_block_number</span> <span class="o">*</span> <span class="n">block_size_in_bytes</span><span class="p">;</span>
             <span class="n">cudaMemcpyAsync</span><span class="p">(</span>
             <span class="n">dst_ptr</span> <span class="o">+</span> <span class="n">dst_offset</span><span class="p">,</span>
             <span class="n">src_ptr</span> <span class="o">+</span> <span class="n">src_offset</span><span class="p">,</span>
             <span class="n">block_size_in_bytes</span><span class="p">,</span>
             <span class="n">memcpy_type</span><span class="p">,</span>
             <span class="n">stream</span><span class="p">);</span>
         <span class="p">}</span>
     <span class="p">}</span>
</code></pre></div> </div> <p>The graph might be useful to understand the vllm structure.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> </div></div> </li> </ol> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/vllm_structure-480.webp 480w,/assets/img/vllm_structure-800.webp 800w,/assets/img/vllm_structure-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/vllm_structure.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    &lt;/div&gt;
&lt;/div&gt;
&lt;div class="caption"&gt;
    A graph of vllm structure.
&lt;/div&gt;



References: [vLL framework](https://zhuanlan.zhihu.com/p/645251151); [vllm](https://github.com/vllm-project/vllm)
</code></pre></div></div>]]></content><author><name></name></author><category term="sample-posts"/><category term="ml"/><summary type="html"><![CDATA[This post is to discuss the swap policy in vllm.]]></summary></entry><entry><title type="html">test</title><link href="https://george-ao.github.io/blog/2024/swap/" rel="alternate" type="text/html" title="test"/><published>2024-04-17T00:00:00+00:00</published><updated>2024-04-17T00:00:00+00:00</updated><id>https://george-ao.github.io/blog/2024/swap</id><content type="html" xml:base="https://george-ao.github.io/blog/2024/swap/"><![CDATA[<p>This theme implements a built-in Jekyll feature, the use of Rouge, for syntax highlighting. It supports more than 100 languages. This example is in C++. All you have to do is wrap your code in markdown code tags:</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">```</span><span class="nl">c++
</span><span class="n">code</span> <span class="n">code</span> <span class="n">code</span>
<span class="p">```</span>
</code></pre></div></div> <div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="kt">char</span> <span class="k">const</span> <span class="err">\</span><span class="o">*</span><span class="n">argv</span><span class="p">[])</span>
<span class="p">{</span>
    <span class="n">string</span> <span class="n">myString</span><span class="p">;</span>

    <span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">"input a string: "</span><span class="p">;</span>
    <span class="n">getline</span><span class="p">(</span><span class="n">cin</span><span class="p">,</span> <span class="n">myString</span><span class="p">);</span>
    <span class="kt">int</span> <span class="n">length</span> <span class="o">=</span> <span class="n">myString</span><span class="p">.</span><span class="n">length</span><span class="p">();</span>

    <span class="kt">char</span> <span class="n">charArray</span> <span class="o">=</span> <span class="k">new</span> <span class="kt">char</span> <span class="o">*</span> <span class="p">[</span><span class="n">length</span><span class="p">];</span>

    <span class="n">charArray</span> <span class="o">=</span> <span class="n">myString</span><span class="p">;</span>
    <span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">length</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">){</span>
        <span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="n">charArray</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&lt;&lt;</span> <span class="s">" "</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">test</span><span class="p">():</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Hello, World!</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <p>For displaying code in a list item, you have to be aware of the indentation, as stated in this <a href="https://stackoverflow.com/questions/34987908/embed-a-code-block-in-a-list-item-with-proper-indentation-in-kramdown/38090598#38090598">Stackoverflow answer</a>. You must indent your code by <strong>(3 * bullet_indent_level)</strong> spaces. This is because kramdown (the markdown engine used by Jekyll) indentation for the code block in lists is determined by the column number of the first non-space character after the list item marker. For example:</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">1.</span> We can put fenced code blocks inside nested bullets, too.
<span class="p">
   1.</span> Like this:<span class="sb">

      ```c
      printf("Hello, World!");
      ```

</span><span class="p">   2.</span> The key is to indent your fenced block in the same line as the first character of the line.
</code></pre></div></div> <p>Which displays:</p> <ol> <li> <p>We can put fenced code blocks inside nested bullets, too.</p> <ol> <li> <p>Like this:</p> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">printf</span><span class="p">(</span><span class="s">"Hello, World!"</span><span class="p">);</span>
</code></pre></div> </div> </li> <li> <p>The key is to indent your fenced block in the same line as the first character of the line.</p> </li> </ol> </li> </ol> <p>By default, it does not display line numbers. If you want to display line numbers for every code block, you can set <code class="language-plaintext highlighter-rouge">kramdown.syntax_highlighter_opts.block.line_numbers</code> to true in your <code class="language-plaintext highlighter-rouge">_config.yml</code> file.</p> <p>If you want to display line numbers for a specific code block, all you have to do is wrap your code in a liquid tag:</p> <p>{% highlight c++ linenos %} <br/> code code code <br/> {% endhighlight %}</p> <p>The keyword <code class="language-plaintext highlighter-rouge">linenos</code> triggers display of line numbers. Produces something like this:</p> <figure class="highlight"><pre><code class="language-c--" data-lang="c++"><table class="rouge-table"><tbody><tr><td class="gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
</pre></td><td class="code"><pre><span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="kt">char</span> <span class="k">const</span> <span class="err">\</span><span class="o">*</span><span class="n">argv</span><span class="p">[])</span>
<span class="p">{</span>
<span class="n">string</span> <span class="n">myString</span><span class="p">;</span>

    <span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">"input a string: "</span><span class="p">;</span>
    <span class="n">getline</span><span class="p">(</span><span class="n">cin</span><span class="p">,</span> <span class="n">myString</span><span class="p">);</span>
    <span class="kt">int</span> <span class="n">length</span> <span class="o">=</span> <span class="n">myString</span><span class="p">.</span><span class="n">length</span><span class="p">();</span>

    <span class="kt">char</span> <span class="n">charArray</span> <span class="o">=</span> <span class="k">new</span> <span class="kt">char</span> <span class="o">*</span> <span class="p">[</span><span class="n">length</span><span class="p">];</span>

    <span class="n">charArray</span> <span class="o">=</span> <span class="n">myString</span><span class="p">;</span>
    <span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">length</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">){</span>
        <span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="n">charArray</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&lt;&lt;</span> <span class="s">" "</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>

<span class="p">}</span>
</pre></td></tr></tbody></table></code></pre></figure>]]></content><author><name></name></author><category term="sample-posts"/><category term="ml"/><summary type="html"><![CDATA[This post is to discuss the swap policy in vllm.]]></summary></entry><entry><title type="html">Linear regression</title><link href="https://george-ao.github.io/blog/2024/ml/" rel="alternate" type="text/html" title="Linear regression"/><published>2024-01-30T00:00:00+00:00</published><updated>2024-01-30T00:00:00+00:00</updated><id>https://george-ao.github.io/blog/2024/ml</id><content type="html" xml:base="https://george-ao.github.io/blog/2024/ml/"><![CDATA[<h4 id="credits-this-post-records-my-learning-of-uiuc-cs44624sp">Credits: This post records my learning of UIUC CS446@24SP.</h4> <p><a href="https://blog.csdn.net/George_here/article/details/135913431">Chinese version</a></p> <h2 id="linear-regression">Linear Regression</h2> <h3 id="simple-case"><em>Simple Case</em></h3> <p>Linear regression is a simple method to solve a regression problem. It has a <strong>closed form</strong> solution. Let me first illustrate how to get the closed form solution. Suppose we have a dataset {\( {(x^1,y^1),…,(x^n,y^n)} \)}, where \(x^i\in\mathbb{R}^d\) and \(y^i\in\mathbb{R}\). We want to find a linear function \(f(x)=w^Tx+b\) to fit the data.</p> <p>To make the question simple, we first discuss the case that d=1, i.e., \(x^i\) is a real number. In this case, we can write the linear function as \(f(x)=w_1x+w_2\). Therefore, what we want to find is the optimal \(w_1\) and \(w_2\) such that \(\underset{w_1,w_2}{\operatorname{argmin}} \frac{1}{2}\sum_{i=1}^n(y^i-w_1x^i-w_2)^2\). Translate the problem into matrix form, we have</p> \[\underset{w_1,w_2}{\operatorname{argmin}} \frac{1}{2} \left\| \begin{bmatrix} y^{1} \\ \vdots \\ y^{n} \end{bmatrix} - \begin{bmatrix} x^{1} &amp; 1 \\ \vdots &amp; \vdots \\ x^{n} &amp; 1 \end{bmatrix} \cdot \begin{bmatrix} w_1 \\ w_2 \end{bmatrix} \right\|^2_2\] <p>Then, we just denote the matrix above as \(X^T, Y, w\) respectively. \( X^T\in \mathbb{R}^{n\times 2}\), Y \(\in \mathbb{R}^{n}\), w \(\in \mathbb{R}^{2}\). The problem becomes \(\underset{w}{\operatorname{argmin}} \frac{1}{2}|Y-Xw|^2_2\). To solve this problem, we just need to take the derivative of the objective function with respect to w and set it to 0. With knowledge of matrix calculus, we have \(L = \frac{1}{2}(Y-X^Tw)^T(Y-X^Tw)= \frac{1}{2}(Y^TY-Y^TX^Tw-w^TXY +w^TX^TXw)\\\)</p> \[\frac{\partial L}{\partial w} = \frac{1}{2}(0-XY-XY+2X^TXw) = 0 \\\] \[w = (X^TX)^{-1}XY\] <h3 id="general-case"><em>General Case</em></h3> <p>Let’s go bakc to general case. We also talk about higher order polynomial regression and $x^i$ is no longer a real number. Suppose we have a dataset \({(x^1,y^1),…,(x^n,y^n)}\), where \(x^i\in\mathbb{R}^d\) and \(y^i\in\mathbb{R}\). We want to find a polynomial function \(f(x)=w_0+w_1x+w_2x^2+…+w_dx^d\) to fit the data. \(\underset{w_0, w_1, \ldots, w_d}{\operatorname{argmin}} \frac{1}{2} \left\| \begin{bmatrix} y^{(1)} \\ \vdots \\ y^{(N)} \end{bmatrix} - \begin{bmatrix} (x^{(1)})^d &amp; \cdots &amp; x^{(1)} &amp; 1 \\ \vdots &amp; \ddots &amp; \vdots &amp; \vdots \\ (x^{(N)})^d &amp; \cdots &amp; x^{(N)} &amp; 1 \end{bmatrix} \cdot \begin{bmatrix} w_d \\ \vdots \\ w_1 \\ w_0 \end{bmatrix} \right\|^2\)</p> <p>Then, X^T \(\in \mathbb{R}^{n\times d}\), Y \(\in \mathbb{R}^{n}\), w \(\in \mathbb{R}^{d}\). The problem is also \(\underset{w}{\operatorname{argmin}} \frac{1}{2}|Y-Xw|^2_2\). Similarly, we can take the derivative of the objective function with respect to w and set it to 0. We get the same closed form solution as above. \(w = (XX^T)^{-1}XY\)</p> <h3 id="regularization"><em>Regularization</em></h3> <p>In practice, we may encounter the problem that \(n&lt;d+1\). In this case, the matrix \(XX^T\) is not invertible. To solve this problem, we can add a regularization term to the objective function. The objective function becomes \(\underset{w}{\operatorname{argmin}} \frac{1}{2}|Y-Xw|^2_2+\frac{\lambda}{2}|w|^2_2\). The closed form solution becomes \(w = (XX^T+\lambda I)^{-1}XY\). Also, regularization can make the parameters smaller and avoid overfitting.</p>]]></content><author><name></name></author><category term="sample-posts"/><category term="ml"/><summary type="html"><![CDATA[This post record my learning of linear regression and logistic regression.]]></summary></entry><entry><title type="html">Displaying External Posts on Your al-folio Blog</title><link href="https://george-ao.github.io/blog/2022/displaying-external-posts-on-your-al-folio-blog/" rel="alternate" type="text/html" title="Displaying External Posts on Your al-folio Blog"/><published>2022-04-23T23:20:09+00:00</published><updated>2022-04-23T23:20:09+00:00</updated><id>https://george-ao.github.io/blog/2022/displaying-external-posts-on-your-al-folio-blog</id><content type="html" xml:base="https://george-ao.github.io/blog/2022/displaying-external-posts-on-your-al-folio-blog/"><![CDATA[]]></content><author><name></name></author></entry></feed>